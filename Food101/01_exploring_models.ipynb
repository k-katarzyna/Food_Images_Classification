{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0b0268a6-3f24-4058-8289-65fb4a9142e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcpara\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ba2b61-b246-4bf1-88ab-128fd6a8d723",
   "metadata": {},
   "source": [
    "# Feature extraction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c97ac4b0-1c09-422b-83b1-590e01748e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extraction_model(base_model_class, input_shape=(IMG_SIZE, IMG_SIZE, 3), preprocess_layer=None, num_classes=101):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        base_model_class: A class for the base model (e.g., tf.keras.applications.MobileNet).\n",
    "        preprocess_layer: Optional preprocessing layer (e.g., tf.keras.layers.Lambda with preprocess function).\n",
    "        input_shape: The shape of the input data (excluding batch size).\n",
    "        num_classes: The number of output classes for classification.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled Keras model.\n",
    "    \"\"\"\n",
    "    if base_model_class == \"Xception\":\n",
    "        input_shape=(299, 299, 3)\n",
    "        \n",
    "    inputs = layers.Input(shape=input_shape, dtype=\"float32\", name=\"input_layer\")\n",
    "    x = layers.Lambda(preprocess_layer, name=\"preprocessing_layer\")(inputs)\n",
    "\n",
    "    base_model = base_model_class(input_tensor=x, include_top=False, weights=\"imagenet\")\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=base_model_class.__name__)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_loss_curves(history, title):\n",
    "    \"\"\"Return separate loss/accuracy curves for training and validation metrics.\"\"\"\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "    accuracy = history.history[\"accuracy\"]\n",
    "    val_accuracy = history.history[\"val_accuracy\"]\n",
    "\n",
    "    epochs = range(len(history.history[\"loss\"]))\n",
    "\n",
    "    plt.figure(figsize=(14,4))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(epochs, loss, label=\"training loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"val loss\")\n",
    "    plt.title(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(epochs, accuracy, label=\"training accuracy\")\n",
    "    plt.plot(epochs, val_accuracy, label=\"val accuracy\")\n",
    "    plt.title(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def test_models(models_config, train_data, test_data, num_classes=101, epochs=3):\n",
    "    \"\"\"\n",
    "    Test various models with different configurations and save the results.\n",
    "    \n",
    "    Args:\n",
    "        models_config (list): List of dicts containing model, its name and preprocessor.\n",
    "        train_data (tf.data.Dataset): Training data.\n",
    "        val_data (tf.data.Dataset): Validation data.\n",
    "        num_classes (int): Number of output classes.\n",
    "        epochs (int): Number of epochs to train the model.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with model performance results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for config in models_config:\n",
    "        model_name = config['model_name']\n",
    "        model_builder = config['model']\n",
    "        preprocess_layer = config['preprocessor']\n",
    "\n",
    "        print(f\"Training model: {model_name}...\")\n",
    "\n",
    "        model = build_feature_extraction_model(model_builder, preprocess_layer=preprocess_layer)\n",
    "\n",
    "        history = model.fit(train_data,\n",
    "                            validation_data=test_data,\n",
    "                            validation_steps=int(0.33*(len(test_data))),\n",
    "                            epochs=epochs,\n",
    "                            verbose=1)\n",
    "\n",
    "        test_accuracy = model.evaluate(test_data)[1]\n",
    "        results.append({\"Model\": model_name,\n",
    "                        \"Test Accuracy\": test_accuracy})\n",
    "\n",
    "        plot_loss_curves(history, model_name)\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results.to_csv(\"feature_extraction_results.csv\", index=False)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ae1bcdd2-7087-450c-84c1-e60727965181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EfficientNetV2S\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"EfficientNetV2S\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast_78 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ preprocessing_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-s (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_52     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ cast_78 (\u001b[38;5;33mCast\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ preprocessing_layer (\u001b[38;5;33mLambda\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetv2-s (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │    \u001b[38;5;34m20,331,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_52     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m101\u001b[0m)            │       \u001b[38;5;34m129,381\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,460,741</span> (78.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,460,741\u001b[0m (78.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">129,381</span> (505.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m129,381\u001b[0m (505.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> (77.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,331,360\u001b[0m (77.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_feature_extraction_model(EfficientNetV2S, preprocess_layer=applications.efficientnet_v2.preprocess_input)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9c96f8f5-0b53-414f-ba4c-17777b1c3dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74843 files belonging to 101 classes.\n",
      "Using 67359 files for training.\n",
      "Using 7484 files for validation.\n",
      "Found 25255 files belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data = image_dataset_from_directory(\"food101_train\",\n",
    "                                                           image_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                                           batch_size=32,\n",
    "                                                           seed=42,\n",
    "                                                           validation_split=0.1,\n",
    "                                                           subset=\"both\"\n",
    "                                                           )\n",
    "\n",
    "\n",
    "train_data = train_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "validation_data = validation_data.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "test_data= image_dataset_from_directory(\"food101_test\",\n",
    "                                          batch_size=32,\n",
    "                                          image_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                          shuffle=False\n",
    "                                        ).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b1534e68-5d11-4934-a509-ff62fe4b4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_config = [\n",
    "    {\n",
    "        'model_name': \"MobileNetV2\",\n",
    "        'model': applications.MobileNetV2,\n",
    "        'preprocessor': applications.mobilenet_v2.preprocess_input\n",
    "    },\n",
    "    {\n",
    "        'model_name': \"EfficientNetV2S\",\n",
    "        'model': EfficientNetV2S,\n",
    "        'preprocessor': applications.efficientnet_v2.preprocess_input\n",
    "    },\n",
    "    {\n",
    "        'model_name': \"Xception\",\n",
    "        'model': applications.Xception,\n",
    "        'preprocessor': applications.xception.preprocess_input,\n",
    "    },\n",
    "    {\n",
    "        'model_name': \"ConvNextTiny\",\n",
    "        'model': applications.ConvNeXtTiny,\n",
    "        'preprocessor': applications.convnext.preprocess_input,\n",
    "    },\n",
    "    {\n",
    "        'model_name': \"ResNet50V2\",\n",
    "        'model': applications.ResNet50V2,\n",
    "        'preprocessor': applications.resnet_v2.preprocess_input,\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b4fea011-b41b-4a3c-9e95-28cfd29e4695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MobileNetV2</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EfficientNetV2S</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xception</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvNextTiny</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ResNet50V2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Model  Test Accuracy\n",
       "0      MobileNetV2           0.04\n",
       "1  EfficientNetV2S           0.71\n",
       "2         Xception           0.06\n",
       "3     ConvNextTiny           0.70\n",
       "4       ResNet50V2           0.14"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = test_models(models_config, train_data, validation_data, test_data, num_classes=101, epochs=3)\n",
    "results_df.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab0d68-27ff-4eb9-92de-71c7810fd66a",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4d44c8-a006-421d-b95e-a0f04e0e9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3d405-46b3-408d-bb02-83d1bfacfcd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "food101",
   "language": "python",
   "name": "food101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
